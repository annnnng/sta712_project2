---
title: "Parametric Bootstrap LMM"
author: "Anh Nguyen"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

# Data

```{r}
music <- read.csv("https://sta279-s22.github.io/labs/music.csv")
```

# Library

```{r message=FALSE, warning=FALSE}
library(lme4)
library(pbkrtest)
library(tidyverse)
```


# Question 1

Test the hypothesis:

+ $H_0: \beta_4 = 0$
+ $H_0: \beta_4 \neq 0$

The reduced model is 

\[\text{Anxiety}_{ij} = \beta_0 + \beta_1\;\text{JuriedPerformance}\]

# Question 2

```{r}
# fit full model
full <- lmer(na ~ audience + large + (1|id), data = music)
summary(full)
# fit reduced model
reduced <- lmer(na ~ audience + (1|id), data = music)
summary(reduced)
```

```{r}
# extract variance
var_reduced <- as.data.frame(VarCorr(reduced))$vcov
var_reduced
```

# Question 3

```{r}
# observed F stats
obs_stat <- KRmodcomp(full, reduced)$stats$Fstat
obs_stat
```

# Question 4

```{r}
# resample group variance
re_new <- rnorm(n = unique(music$id), mean = 0, sd = var_reduced[1])
```

# Question 5

```{r}
# resample individuals variance
noise_new <- rnorm(n = nrow(music), mean = 0, sd = var_reduced[2])
```

```{r}
fitted_values <- predict(reduced, re.form=NA)
re_data <- data.frame(id = unique(music$id),
                      re = re_new) %>%
  right_join(dplyr::select(music, id), by = "id")
new_data <- data.frame(id = music$id,
                       audience = music$audience,
                       large = music$large,
                       na = fitted_values + re_data$re + noise_new)
```

# Question 6

```{r}
full_sim <- lmer(na ~ audience + large + (1|id), data = new_data)
reduced_sim <- lmer(na ~ audience + (1|id), data = new_data)
```

# Question 7

```{r}
KRmodcomp(full_sim, reduced_sim)$stats$Fstat
```

# Question 8

```{r}
nsim <- 500
f_stats <- rep(NA, nsim)

for(sim in 1:nsim){
  # code from steps 2 and 3 goes here!
  # bootstrap new data
  re_new <- rnorm(n = unique(music$id), mean = 0, sd = var_reduced[1])
  noise_new <- rnorm(n = nrow(music), mean = 0, sd = var_reduced[2])
  fitted_values <- predict(reduced, re.form=NA)
  re_data <- data.frame(id = unique(music$id),
                        re = re_new) %>%
    right_join(dplyr::select(music, id), by = "id")
  new_data <- data.frame(id = music$id,
                         audience = music$audience,
                         large = music$large,
                         na = fitted_values + re_data$re + noise_new)
  # refit model
  full_sim <- lmer(na ~ audience + large + (1|id), data = new_data)
  reduced_sim <- lmer(na ~ audience + (1|id), data = new_data)
  # remember to save the results in f_stats
  f_stats[sim] <- KRmodcomp(full_sim, reduced_sim)$stats$Fstat
}
```


# Question 9

```{r}
mean(f_stats > obs_stat)
```

The p-value is 0, so we fail to reject the null hypothesis. There is no evidence for a difference in anxiety levels between large and small ensemble performances, after accounting for audience type.

# Question 10 

```{r}
KRmodcomp(full, reduced)
```

The p-value for from the chi-squared distribution is only $10^{-3}$ order away from the p-value from the bootstrap. If we increase the number of simulation, the p-value might be the same.

# Question 11

The p-values for the bootstrap can take any values from 0 to somewhere in the $10^{-2}$ order. This is because we are averaging over 500 simulations. If we increase our simulation, we can get more significant figures for our p-values.